{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c9a674-43d9-4328-b42a-8a9be7423cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 API 키 불러오기\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e35ea2-b820-417b-9694-e33193eb8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(api_key) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7752f0-5743-4d63-9afd-c00a5a4dfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf46774-6615-4bed-8e64-fc4a53b1b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"인공지능최신동향.pdf\"\n",
    "# PDF 파일 경로\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7aab7c-dff4-43fd-a581-7c4a4f90df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2024년 11월호\n",
      "['source', 'page']\n"
     ]
    }
   ],
   "source": [
    "page_number = docs[1].metadata['page']\n",
    "print(page_number)\n",
    "page_text = docs[0].page_content\n",
    "print(page_text)\n",
    "print(list(docs[0].metadata.keys())) # matadata의 key가 어떤것들이 있는지 확인 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5944d570-6914-46dd-aefd-c5c472b8c0f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits = recursive_text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e721d217-a848-4e88-ab5e-39d1ec80c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "# 로컬 파일 저장소 설정\n",
    "store = LocalFileStore(\"C:\\\\Users\\\\1\\\\Desktop\\\\emb\")\n",
    "\n",
    "# 캐시를 지원하는 임베딩 생성 - 임베딩시 계속 api 호출을 방지하기 위해 로컬에 임베팅 파일을 저장하는 형식\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=embeddings,\n",
    "    document_embedding_cache=store,\n",
    "    namespace=embeddings.model,  # 기본 임베딩과 저장소를 사용하여 캐시 지원 임베딩을 생성\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798e7236-0786-4691-ba7b-ade214e854cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "    \n",
    "    \n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9a76ed-8c52-4a3a-8fcb-853f73e049d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # 가져올 청크 수를 3으로 늘림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202808b-7458-4c92-94f4-9fa084ccfdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디버그 및 컨텍스트 처리 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f9bcf3d-bec0-421c-be83-9b4a9d562489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableMap\n",
    "\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "# 문서 리스트를 텍스트로 변환하는 단계 추가\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  # config 인수 추가\n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"question\": inputs[\"question\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616192ed-6ebd-4aff-8344-4a3c019ec31c",
   "metadata": {},
   "source": [
    " 프롬프트 파싱 함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ddb52e2-bc2e-4260-a297-bffeed579640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chat_prompt_template(prompt_path):\n",
    "    '''\n",
    "    프롬프트 경로에서 프롬프트 파일을 읽어 시스템 메시지와 사용자 메시지로 분리하고\n",
    "    이를 사용하여 ChatPromptTemplate을 생성\n",
    "    '''\n",
    "    with open(prompt_path, 'r', encoding='utf-8') as file:\n",
    "        prompt_text = file.read()\n",
    "    # 'system'과 'human'으로 분리\n",
    "    sections = prompt_text.strip().split('human') # 문자열 양쪽에 공백 제거 후, 'human'찾아 섹션을 나누고 리스트로 분리하기 \n",
    "\n",
    "    # 정의 부분\n",
    "    system_prompt = '' \n",
    "    user_prompt = ''\n",
    "    if len(sections) == 2: # system과 human으로 분리되어 있을 때\n",
    "        system_prompt = sections[0].replace('system', '').strip()\n",
    "        user_prompt = sections[1].strip()\n",
    "    else:\n",
    "        user_prompt = prompt_text.strip() # 아니면 바로 user_prompt로 할당.\n",
    "    # 메시지 리스트 생성\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append((\"system\", system_prompt))\n",
    "    if user_prompt:\n",
    "        messages.append((\"user\", user_prompt))\n",
    "    # ChatPromptTemplate 생성\n",
    "    prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8894cadf-2b15-491a-82c9-529c6d8ed3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 생성 함수\n",
    "def create_rag_chain(prompt_template, retriever, model):\n",
    "    chain = (\n",
    "        RunnableMap({\n",
    "            \"question\": DebugPassThrough(),\n",
    "            \"context\": retriever\n",
    "        })\n",
    "        | ContextToText()\n",
    "        | prompt_template\n",
    "        | model\n",
    "    )\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5f05a93-f8da-4ae5-ab7c-796fb32dfaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# 타임스탬프 생성\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# 프롬프트 및 응답 폴더 설정\n",
    "prompt_folder = 'Prompts'\n",
    "prompt_files = [f for f in os.listdir(prompt_folder) if f.endswith('.txt')]\n",
    "output_folder = 'responses'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26e250a9-e9c1-40f1-b45b-a8dd2c5824fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug Output: 주요 행사 일정의 개요를 정리해줘\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(query)\n",
    "print(type(response.content))  # <class 'dict'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68b42f7a-09a6-4640-aec5-3e583c4b9cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 빈 줄 입력):  주요 행사 일정의 개요를 정리해줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using prompt from Prompt1.txt\n",
      "Debug Output: 주요 행사 일정의 개요를 정리해줘\n",
      "Final Response:\n",
      "주요 행사 일정은 다음과 같습니다:\n",
      "\n",
      "1. **NeurIPS 2024**\n",
      "   - 기간: 2024.12.10~15\n",
      "   - 장소: 캐나다 밴쿠버\n",
      "   - 개요: 인공지능과 머신러닝 분야의 연구 성과 교환을 촉진하는 연례 학술대회로, AI 연구자를 위한 실험 설계, LLM을 위한 메타 생성 알고리즘, 정렬에 대한 학제 간 통찰력 등을 다룰 예정.\n",
      "   - 홈페이지: [neurips.cc](https://neurips.cc/)\n",
      "\n",
      "2. **GenAI Summit Maroc 2024**\n",
      "   - 기간: 2024.12.10~11\n",
      "   - 장소: 모로코\n",
      "   - 개요: 인공지능과 데이터 분석에 초점을 맞춘 행사로, 250명 이상의 업계 리더, 정책 입안자, 전문가가 모여 AI 발전을 탐구하며, 오픈소스 AI, AI 주도 사이버 보안 등을 다룰 예정.\n",
      "   - 홈페이지: [genaimaroc.com](https://genaimaroc.com/)\n",
      "\n",
      "3. **AI Summit Seoul 2024**\n",
      "   - 기간: 2024.12.10~11\n",
      "   - 장소: 서울(코엑스 그랜드볼룸)\n",
      "   - 개요: AI와 산업의 융합에 초점을 두고 다양한 글로벌 기업과 기관, 학계 전문가들이 모여 AI 및 산업 트렌드에 대한 주제 발표 및 워크샵을 진행.\n",
      "   - 홈페이지: [aisummit.co.kr](https://aisummit.co.kr/)\n",
      "Response saved to Prompt1_20241115_142347_result.txt\n",
      "\n",
      "Using prompt from Prompt2.txt\n",
      "Debug Output: 주요 행사 일정의 개요를 정리해줘\n",
      "Final Response:\n",
      "주요 행사 일정은 다음과 같습니다:  \n",
      "1. NeurIPS 2024 - 2024년 12월 10일부터 15일까지 캐나다 밴쿠버에서 개최.  \n",
      "2. GenAI Summit Maroc 2024 - 2024년 12월 10일부터 11일까지 모로코에서 개최.  \n",
      "3. AI Summit Seoul 2024 - 2024년 12월 10일부터 11일까지 서울 코엑스에서 개최.\n",
      "Response saved to Prompt2_20241115_142347_result.txt\n",
      "\n",
      "Using prompt from Prompt3.txt\n",
      "Debug Output: 주요 행사 일정의 개요를 정리해줘\n",
      "Final Response:\n",
      "주요 행사 일정의 개요는 다음과 같습니다:\n",
      "\n",
      "1. **NeurIPS 2024**\n",
      "   - **목적**: 인공지능과 머신러닝 분야의 연구 성과 교환 촉진\n",
      "   - **기간**: 2024.12.10~15\n",
      "   - **장소**: 캐나다 밴쿠버\n",
      "   - **홈페이지**: [neurips.cc](https://neurips.cc/)\n",
      "\n",
      "2. **GenAI Summit Maroc 2024**\n",
      "   - **목적**: 인공지능과 데이터 분석에 초점을 맞춘 행사, 업계 리더 및 전문가들이 AI 발전 탐구\n",
      "   - **기간**: 2024.12.10~11\n",
      "   - **장소**: 모로코\n",
      "   - **홈페이지**: [genaimaroc.com](https://genaimaroc.com/)\n",
      "\n",
      "3. **AI Summit Seoul 2024**\n",
      "   - **목적**: AI와 산업의 융합에 초점을 두고 다양한 전문가들이 모여 주제 발표 및 워크샵 진행\n",
      "   - **기간**: 2024.12.10~11\n",
      "   - **장소**: 서울(코엑스 그랜드볼룸)\n",
      "   - **홈페이지**: [aisummit.co.kr](https://aisummit.co.kr/)\n",
      "Response saved to Prompt3_20241115_142347_result.txt\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 빈 줄 입력):   \n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요 (종료하려면 빈 줄 입력): \")\n",
    "    if not query.strip():\n",
    "        break\n",
    "    for prompt_file in prompt_files:\n",
    "        prompt_path = os.path.join(prompt_folder, prompt_file)\n",
    "        prompt_template = load_chat_prompt_template(prompt_path)\n",
    "        chain = create_rag_chain(prompt_template, retriever, model)\n",
    "        print(f\"\\nUsing prompt from {prompt_file}\")\n",
    "        response = chain.invoke(query) # 문자열 요구 chain.invoke({\"question\": query}) -> chain.invoke(query) 수정\n",
    "        print(\"Final Response:\")\n",
    "        print(response.content)\n",
    "        # 응답 저장\n",
    "        output_file = f\"{os.path.splitext(prompt_file)[0]}_{timestamp}_result.txt\"\n",
    "        output_path = os.path.join(output_folder, output_file)\n",
    "        with open(output_path, 'a', encoding='utf-8') as file:\n",
    "            file.write(\"\\nQuestion: \" + query + \"\\nResponse: \" + response.content + \"\\n\")\n",
    "        print(f\"Response saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e725c12-66d9-41d1-b260-ae3db83c1ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
